{"_path":"/modules/performance-optimization-and-parallelization/info","_dir":"performance-optimization-and-parallelization","_draft":false,"_partial":false,"_locale":"","title":"Learning objectives","description":"After completing unit 5 you will have acquired a basic concept of performance optimization and parallelization like speedup, scalability, Amdahl’s and Gustafson’s laws, how to design parallel programs, domain decomposition, synchronization, etc.","type":"info","order":0,"body":{"type":"root","children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"After completing unit 5 you will have acquired a basic concept of performance optimization and parallelization like speedup, scalability, Amdahl’s and Gustafson’s laws, how to design parallel programs, domain decomposition, synchronization, etc."}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Understand Parallel Computing Architectures: Learners will be able to describe the classification of modern computing resources based on hardware-supported parallelism, including multi-core systems, multi-processor machines, clusters, and cloud infrastructures."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Analyze Performance Optimization in Parallel Programming: Learners will be able to identify key performance considerations in parallel programming and explain how to optimize programs to effectively utilize available computing power."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Apply Basic Parallel Programming Concepts"},{"type":"element","tag":"div","props":{},"children":[]},{"type":"text","value":" will be able to write and analyze simple parallel programs using insights from the Livermore Computing Center tutorial and Mats Brorsson's lecture, focusing on performance optimization and resource utilization."},{"type":"element","tag":"br","props":{},"children":[]}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"local_fs:modules:Performance-optimization-and-parallelization:info.md","_source":"local_fs","_file":"modules/Performance-optimization-and-parallelization/info.md","_stem":"modules/Performance-optimization-and-parallelization/info","_extension":"md","plainText":"---\ntitle: Learning objectives\ntype: info\norder: 0\n---\n\nAfter completing unit 5 you will have acquired a basic concept of performance optimization and parallelization like speedup, scalability, Amdahl’s and Gustafson’s laws, how to design parallel programs, domain decomposition, synchronization, etc.\n\n- Understand Parallel Computing Architectures: Learners will be able to describe the classification of modern computing resources based on hardware-supported parallelism, including multi-core systems, multi-processor machines, clusters, and cloud infrastructures.\n\n- Analyze Performance Optimization in Parallel Programming: Learners will be able to identify key performance considerations in parallel programming and explain how to optimize programs to effectively utilize available computing power.\n\n- Apply Basic Parallel Programming Concepts:Learners will be able to write and analyze simple parallel programs using insights from the Livermore Computing Center tutorial and Mats Brorsson's lecture, focusing on performance optimization and resource utilization.\n"}